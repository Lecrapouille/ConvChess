\cleardoublepage

\begin{center}
	\huge{\textbf{Abstract}}
\end{center}

How well can one play chess without domain knowledge?  
Most such systems play so poorly that the question has not
been explored much.  Chess is a deterministic game, and it is assumed
that it would be solved by extensive search-based paradigms.  Though such 
approaches today perform far above human levels, such methods are weak in 
strategy, since the ideas cannot be generalized to ``similar positions''. On 
the other hand, strong human players have strategies that seem to be based on 
pattern-driven implicit knowledge rather than explicit search.  Can such 
approaches contribute to machine chess? 

In this thesis we explore this question by training a chess machine that
learns merely by observing several thousand unannotated games between good
human players, along with outcome. The system uses the moves played in each
position as an oracle and uses a convolutional neural net to learn a 
representation for the board.  This model is then tuned with back-propagation 
for a) learning the piece to be moved, b) learning which move to make given a 
piece, and c) learning to estimate the win-probability for a given board.   We 
had very limited expectations of the system, and worried that it may not even 
learn the rules of the game.  However, we found that the system not only plays
legally correct moves (including complex situations such as castling, en
passant or promotion), but finds fairly good moves in almost all board
situations (the move actually played in the test set is almost always one of
the top five moves).  Further, the evaluation function, which is trained by
discounting outcomes based on distance from the end.  The system is able to
beat a fairly decent machine (Sunfish, \cite{sunfish}) in 21.6\% of games, even 
without any opening book.
